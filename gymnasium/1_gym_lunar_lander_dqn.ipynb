{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cb53f9",
   "metadata": {},
   "source": [
    "# Lunar Lander with Gymnasium and Deep Q-Learning (DQN)\n",
    "\n",
    "DQN is an off-policy reinforcement learning algorithm that learns an action-value function Q(s,a)Q(s,a), which estimates the expected future reward of taking action aa in state ss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a3efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888408f",
   "metadata": {},
   "source": [
    "## Create the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14db406",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeff109",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b2720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.5     |\n",
      "|    ep_rew_mean      | -154     |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2452     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2106     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 813      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -146     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1267     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1144     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.41     |\n",
      "|    n_updates        | 35       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.4     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1100     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1446     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 111      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.2     |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1001     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1844     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 210      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.7     |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 911      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2248     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.52     |\n",
      "|    n_updates        | 311      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94       |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2632     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.664    |\n",
      "|    n_updates        | 407      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.9     |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 769      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3006     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 501      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.1     |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 753      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3422     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.52     |\n",
      "|    n_updates        | 605      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -160     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 745      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 3907     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 726      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4350     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 837      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4762     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 940      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | -151     |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 479      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 6094     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.912    |\n",
      "|    n_updates        | 1273     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | -148     |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 484      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 6586     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.785    |\n",
      "|    n_updates        | 1396     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | -143     |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 489      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 7190     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.645    |\n",
      "|    n_updates        | 1547     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | -138     |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 475      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 7846     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.782    |\n",
      "|    n_updates        | 1711     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | -132     |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 9149     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 2037     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | -127     |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 9822     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.703    |\n",
      "|    n_updates        | 2205     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 138      |\n",
      "|    ep_rew_mean      | -122     |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 10462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 2365     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | -118     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 11639    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 2659     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 176      |\n",
      "|    ep_rew_mean      | -112     |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 14794    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.372    |\n",
      "|    n_updates        | 3448     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 214      |\n",
      "|    ep_rew_mean      | -111     |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 18794    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 4448     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 244      |\n",
      "|    ep_rew_mean      | -114     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 22469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.972    |\n",
      "|    n_updates        | 5367     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 262      |\n",
      "|    ep_rew_mean      | -117     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 312      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 25148    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.578    |\n",
      "|    n_updates        | 6036     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 276      |\n",
      "|    ep_rew_mean      | -116     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 309      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 27557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.699    |\n",
      "|    n_updates        | 6639     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -115     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 301      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 31088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 7521     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 320      |\n",
      "|    ep_rew_mean      | -114     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 304      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 32789    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.833    |\n",
      "|    n_updates        | 7947     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 351      |\n",
      "|    ep_rew_mean      | -111     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 305      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 36257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.466    |\n",
      "|    n_updates        | 8814     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 371      |\n",
      "|    ep_rew_mean      | -101     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 303      |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 38578    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.448    |\n",
      "|    n_updates        | 9394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 395      |\n",
      "|    ep_rew_mean      | -93.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 300      |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 41343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.495    |\n",
      "|    n_updates        | 10085    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 431      |\n",
      "|    ep_rew_mean      | -89      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 279      |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 45343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 11085    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 459      |\n",
      "|    ep_rew_mean      | -84.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 278      |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 48515    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.609    |\n",
      "|    n_updates        | 11878    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 489      |\n",
      "|    ep_rew_mean      | -76.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 51885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.937    |\n",
      "|    n_updates        | 12721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 525      |\n",
      "|    ep_rew_mean      | -74.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 55885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 13721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 560      |\n",
      "|    ep_rew_mean      | -67.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 259      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 59885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.735    |\n",
      "|    n_updates        | 14721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 595      |\n",
      "|    ep_rew_mean      | -60.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 248      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 63885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.543    |\n",
      "|    n_updates        | 15721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 631      |\n",
      "|    ep_rew_mean      | -58      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 248      |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 67885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 16721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 658      |\n",
      "|    ep_rew_mean      | -54.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 249      |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 71885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 17721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | -50.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 250      |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 75885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.413    |\n",
      "|    n_updates        | 18721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 727      |\n",
      "|    ep_rew_mean      | -47.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 79885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.459    |\n",
      "|    n_updates        | 19721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | -40      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 254      |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 82462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 20365    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | -39      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 255      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 86462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.333    |\n",
      "|    n_updates        | 21365    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | -36.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 257      |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 89871    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 22217    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | -35.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 258      |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 93107    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 23026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 855      |\n",
      "|    ep_rew_mean      | -33.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 97107    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 24026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | -33.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 385      |\n",
      "|    total_timesteps  | 101107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 25026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 854      |\n",
      "|    ep_rew_mean      | -30.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total_timesteps  | 104225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.315    |\n",
      "|    n_updates        | 25806    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 858      |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 263      |\n",
      "|    time_elapsed     | 411      |\n",
      "|    total_timesteps  | 108223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 26805    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 871      |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 261      |\n",
      "|    time_elapsed     | 428      |\n",
      "|    total_timesteps  | 112223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 27805    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 878      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total_timesteps  | 115344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.469    |\n",
      "|    n_updates        | 28585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 877      |\n",
      "|    ep_rew_mean      | -2.76    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 259      |\n",
      "|    time_elapsed     | 457      |\n",
      "|    total_timesteps  | 118792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.192    |\n",
      "|    n_updates        | 29447    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 900      |\n",
      "|    ep_rew_mean      | 2.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 258      |\n",
      "|    time_elapsed     | 474      |\n",
      "|    total_timesteps  | 122792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 30447    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 905      |\n",
      "|    ep_rew_mean      | 5.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 257      |\n",
      "|    time_elapsed     | 491      |\n",
      "|    total_timesteps  | 126792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 31447    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 913      |\n",
      "|    ep_rew_mean      | 5.34     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 256      |\n",
      "|    time_elapsed     | 507      |\n",
      "|    total_timesteps  | 129895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 32223    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 919      |\n",
      "|    ep_rew_mean      | 8.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 255      |\n",
      "|    time_elapsed     | 520      |\n",
      "|    total_timesteps  | 133209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 33052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 919      |\n",
      "|    ep_rew_mean      | 8.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 254      |\n",
      "|    time_elapsed     | 539      |\n",
      "|    total_timesteps  | 137209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 34052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 927      |\n",
      "|    ep_rew_mean      | 8.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 252      |\n",
      "|    time_elapsed     | 558      |\n",
      "|    total_timesteps  | 141209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 35052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 933      |\n",
      "|    ep_rew_mean      | 6.71     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 252      |\n",
      "|    time_elapsed     | 575      |\n",
      "|    total_timesteps  | 145209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.749    |\n",
      "|    n_updates        | 36052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 922      |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 251      |\n",
      "|    time_elapsed     | 587      |\n",
      "|    total_timesteps  | 148074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 36768    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 906      |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 594      |\n",
      "|    total_timesteps  | 150533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 37383    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 902      |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 608      |\n",
      "|    total_timesteps  | 154107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 38276    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 885      |\n",
      "|    ep_rew_mean      | 29       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 252      |\n",
      "|    time_elapsed     | 618      |\n",
      "|    total_timesteps  | 156426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 38856    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 875      |\n",
      "|    ep_rew_mean      | 35.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 628      |\n",
      "|    total_timesteps  | 159343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 39585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 871      |\n",
      "|    ep_rew_mean      | 38.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 642      |\n",
      "|    total_timesteps  | 163012   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 40502    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 855      |\n",
      "|    ep_rew_mean      | 44.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 653      |\n",
      "|    total_timesteps  | 165423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0857   |\n",
      "|    n_updates        | 41105    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 859      |\n",
      "|    ep_rew_mean      | 46.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 252      |\n",
      "|    time_elapsed     | 665      |\n",
      "|    total_timesteps  | 168327   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 41831    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 842      |\n",
      "|    ep_rew_mean      | 49.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 673      |\n",
      "|    total_timesteps  | 170679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 42419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 253      |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total_timesteps  | 172689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.65     |\n",
      "|    n_updates        | 42922    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 814      |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 254      |\n",
      "|    time_elapsed     | 685      |\n",
      "|    total_timesteps  | 174496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 43373    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 255      |\n",
      "|    time_elapsed     | 694      |\n",
      "|    total_timesteps  | 177120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 44029    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | 72       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 256      |\n",
      "|    time_elapsed     | 698      |\n",
      "|    total_timesteps  | 178906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 44476    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 76.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 255      |\n",
      "|    time_elapsed     | 711      |\n",
      "|    total_timesteps  | 182092   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 45272    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 757      |\n",
      "|    ep_rew_mean      | 84.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 256      |\n",
      "|    time_elapsed     | 716      |\n",
      "|    total_timesteps  | 183942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.27     |\n",
      "|    n_updates        | 45735    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DQN model\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",         # Use a Multi-Layer Perceptron (MLP) neural network\n",
    "    env=env,                    # The Gym environment\n",
    "    \n",
    "    # === Learning Parameters ===\n",
    "    learning_rate=1e-3,         # Step size for optimizer (Adam by default). Higher = faster but riskier updates.\n",
    "\n",
    "    # === Replay Buffer ===\n",
    "    buffer_size=50_000,         # Max number of past transitions to store. Larger = more stable learning but more memory.\n",
    "    learning_starts=1000,       # Number of steps before learning starts (helps fill the buffer with diverse experience).\n",
    "    batch_size=64,              # Number of samples per training update from the buffer.\n",
    "\n",
    "    # === Discounting and Target Network ===\n",
    "    gamma=0.99,                 # Discount factor for future rewards. Close to 1 = long-term reward focus.\n",
    "    tau=1.0,                    # Soft update rate for the target network. 1.0 = hard update every target_update_interval.\n",
    "\n",
    "    # === Training Frequency ===\n",
    "    train_freq=4,               # Train the model every 4 environment steps.\n",
    "    target_update_interval=1000,  # Number of training steps between target network updates (delayed update stabilizes learning).\n",
    "\n",
    "    # === Misc Settings ===\n",
    "    verbose=1,                  # Verbosity level: 0 = silent, 1 = training info, 2 = debug.\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=200_000)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"dqn_lunarlander\")\n",
    "\n",
    "# Evaluate the model\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63355818",
   "metadata": {},
   "source": [
    "## Interpretting Training Log\n",
    "\n",
    "| Metric                        | Meaning                                                                                                                                                                                           |\n",
    "| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`ep_len_mean`**       | Average number of steps per episode. Max is 1000 for `LunarLander-v3`, so a high number means your agent usually survives (or crashes) near the end of each episode.                                        |\n",
    "| **`ep_rew_mean`**      | Average reward per episode over recent rollouts. In `LunarLander`, good agents score **\\~200**, random ones score near **0 or below**. A score below 200 indicates your agent hasn't converged yet. |\n",
    "| **`exploration_rate`** = 0.05 | Current  in -greedy exploration. Starts near 1 (more random) and decays to min (usually 0.05). Youre now mostly exploiting learned policy.                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8aadd7",
   "metadata": {},
   "source": [
    "## Render the Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329acabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"dqn_lunarlander\")\n",
    "\n",
    "# Create environment with human rendering\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3696d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
